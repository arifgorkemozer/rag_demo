{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da008d2d",
      "metadata": {
        "id": "da008d2d"
      },
      "source": [
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a44445",
      "metadata": {
        "id": "75a44445",
        "outputId": "78a0b9bc-0551-4f6e-8db4-09f4128225e0"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq ipykernel==6.29.5 --progress-bar off\n",
        "!pip install -qqq pandas==2.2.3 --progress-bar off\n",
        "!pip install -qqq pdfminer --progress-bar off            \n",
        "!pip install -qqq pdfminer.six --progress-bar off       \n",
        "!pip install -qqq sqlite-vec==0.1.1 --progress-bar off   \n",
        "!pip install -qqq fastembed==0.3.4 --progress-bar off    \n",
        "!pip install -qqq rank-bm25==0.2.2 --progress-bar off  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "200dd743",
      "metadata": {
        "id": "200dd743"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "439f44ca",
      "metadata": {
        "id": "439f44ca"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import requests\n",
        "import sqlite3\n",
        "import sqlite_vec\n",
        "from fastembed import TextEmbedding\n",
        "from pdfminer.high_level import extract_text\n",
        "from rank_bm25 import BM25Okapi\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d870d562",
      "metadata": {
        "id": "d870d562"
      },
      "source": [
        "Define constants and global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ff3ffc",
      "metadata": {
        "id": "39ff3ffc"
      },
      "outputs": [],
      "source": [
        "DB_NAME = \"metu_academic\"\n",
        "TABLE_NAME = \"metu_academic_rules\"\n",
        "ORIG_DOCS_FOLDER = \"./docs\"\n",
        "TEXT_DOCS_FOLDER = \"./docs_text\"\n",
        "\n",
        "all_paragraphs = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05e5d6f3",
      "metadata": {
        "id": "05e5d6f3"
      },
      "source": [
        "Create SQLite database file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4a1465",
      "metadata": {
        "id": "0d4a1465"
      },
      "outputs": [],
      "source": [
        "db = sqlite3.connect(DB_NAME + \".db\")\n",
        "db.enable_load_extension(True)\n",
        "sqlite_vec.load(db)\n",
        "db.enable_load_extension(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9ca555",
      "metadata": {},
      "source": [
        "Create document metadata and embeddings tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2b4307",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop metadata table if exists before\n",
        "db.execute(f\"DROP TABLE IF EXISTS {TABLE_NAME};\")\n",
        "\n",
        "# create metadata table\n",
        "db.execute(f\"\"\"\n",
        "        CREATE TABLE {TABLE_NAME} (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            text TEXT NOT NULL\n",
        "        );\n",
        "    \"\"\")\n",
        "\n",
        "# drop embedding table if exists before\n",
        "db.execute(f\"DROP TABLE IF EXISTS document_embeddings;\")\n",
        "\n",
        "# create embedding table, default vector length for fastembed is 384\n",
        "db.execute(\n",
        "    f\"\"\"\n",
        "        CREATE VIRTUAL TABLE document_embeddings USING vec0(\n",
        "        id INTEGER PRIMARY KEY,\n",
        "        embedding FLOAT[384]\n",
        "        );\n",
        "    \"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2dce323",
      "metadata": {
        "id": "e2dce323"
      },
      "source": [
        "Convert not processed PDF documents to .txt documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03988e38",
      "metadata": {
        "id": "03988e38"
      },
      "outputs": [],
      "source": [
        "def pdf_to_text(pdf_path, txt_path):\n",
        "    text = extract_text(pdf_path)\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
        "        txt_file.write(text)\n",
        "\n",
        "not_processed_files = [fname for fname in os.listdir(f\"./{ORIG_DOCS_FOLDER}\") if f\"{fname}.txt\" not in os.listdir(f\"./{TEXT_DOCS_FOLDER}\")]\n",
        "print(\"These files will be processed:\")\n",
        "pprint.pprint(not_processed_files)\n",
        "\n",
        "for fname in not_processed_files:\n",
        "    pdf_to_text(f\"./{ORIG_DOCS_FOLDER}/{fname}\", f\"./{TEXT_DOCS_FOLDER}/{fname}.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1625ab",
      "metadata": {
        "id": "6a1625ab"
      },
      "source": [
        "Add new paragraphs and their embeddings to the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b019754c",
      "metadata": {
        "id": "b019754c",
        "outputId": "775c9f84-906a-4179-f868-c585a283aa31"
      },
      "outputs": [],
      "source": [
        "# read not processed files\n",
        "new_paragraph_ids = []\n",
        "last_paragraph_id = len(all_paragraphs.keys())\n",
        "\n",
        "print(\"Last paragraph ID:\", last_paragraph_id)\n",
        "\n",
        "for fname in not_processed_files:\n",
        "    text_filename = f\"{fname}.txt\"\n",
        "    print(f\"Processing: {text_filename}\")\n",
        "\n",
        "    content_file = open(f\"./{TEXT_DOCS_FOLDER}/{text_filename}\", \"r\")\n",
        "    content_lines = content_file.readlines()\n",
        "    full_content = \"\".join(content_lines)\n",
        "\n",
        "    \"\"\"\n",
        "    For this demo, paragraphs are important for us.\n",
        "    Paragraphs are identified by double newline characters.\n",
        "    The assumptions for paragraphs are: they should have length more than 100 characters and they should contain dot character.\n",
        "    \"\"\"\n",
        "    new_paragraphs_text = [text_block for text_block in full_content.split(\"\\n\\n\") if text_block.strip() != \"\" and len(text_block.split(\" \")) > 1 and \".\" in text_block and len(text_block) > 100]\n",
        "\n",
        "    for i, paragraph in enumerate(new_paragraphs_text):\n",
        "        orig_fname = text_filename[0 : -4] # remove .txt at the end\n",
        "        new_paragraph_id = last_paragraph_id + i + 1\n",
        "        all_paragraphs[new_paragraph_id] = (orig_fname, paragraph)\n",
        "        new_paragraph_ids.append(new_paragraph_id)\n",
        "    \n",
        "    last_paragraph_id = len(all_paragraphs.keys())\n",
        "    print(\"Last paragraph ID:\", last_paragraph_id)\n",
        "\n",
        "\n",
        "# add new paragraphs to the metadata table\n",
        "for new_paragraph_id in new_paragraph_ids:\n",
        "    db.execute(f\"\"\"INSERT INTO {TABLE_NAME}(id, text) VALUES (?, ?)\"\"\", [new_paragraph_id, all_paragraphs[new_paragraph_id][1]])\n",
        "\n",
        "#Â add new paragraph embeddings to the database\n",
        "model = TextEmbedding()\n",
        "\n",
        "# convert to embeddings\n",
        "document_embeddings = list(model.embed([all_paragraphs[new_paragraph_id][1] for new_paragraph_id in new_paragraph_ids]))\n",
        "\n",
        "for i in range(len(new_paragraph_ids)):\n",
        "    db.execute(f\"\"\"INSERT INTO document_embeddings(id, embedding) VALUES (?, ?)\"\"\", [new_paragraph_ids[i], sqlite_vec.serialize_float32(document_embeddings[i])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9289868",
      "metadata": {},
      "outputs": [],
      "source": [
        "document_embeddings[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a67f80e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    return re.findall(r\"[\\\\w']+\", text.lower())\n",
        "\n",
        "# Build BM25 corpus (list of tokenized docs)\n",
        "corpus = [tokenize(p[1]) for p in all_paragraphs.values()]\n",
        "bm25 = BM25Okapi(corpus)\n",
        "doc_ids = list(all_paragraphs.keys())  # maintain mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf65367",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Retrieve related paragraphs using BM25 ---\n",
        "def get_bm25_paragraphs(query, top_k=5):\n",
        "    tokenized_query = tokenize(query)\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    # sort docs by score\n",
        "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
        "\n",
        "    related_paragraphs = [all_paragraphs[doc_ids[i]][1] for i in top_indices]\n",
        "    return related_paragraphs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b8e9ce",
      "metadata": {
        "id": "c3b8e9ce"
      },
      "source": [
        "Search similar documents and generate enriched LLM prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bba66f7",
      "metadata": {
        "id": "2bba66f7",
        "outputId": "b3bdfcd7-498b-4e05-b10f-5751fbb41e51"
      },
      "outputs": [],
      "source": [
        "def get_enriched_llm_prompt(basic_prompt, number_of_examples, rag_option=\"both\"): # \"both\", \"bm25\", \"vector\"  \n",
        "    query_embedding = list(model.embed(basic_prompt))[0]\n",
        "\n",
        "    results = db.execute(\n",
        "        f\"\"\"\n",
        "        SELECT\n",
        "            document_embeddings.id,\n",
        "            distance,\n",
        "            {TABLE_NAME}.text\n",
        "        FROM document_embeddings\n",
        "        LEFT JOIN {TABLE_NAME} ON {TABLE_NAME}.id = document_embeddings.id\n",
        "        WHERE document_embeddings.embedding MATCH ?\n",
        "            AND k = ?\n",
        "        ORDER BY distance\n",
        "        \"\"\",\n",
        "        [sqlite_vec.serialize_float32(query_embedding), number_of_examples],\n",
        "    ).fetchall()\n",
        "\n",
        "    related_paragraphs = [item[2] for item in results]\n",
        "    bm25_paragraphs = get_bm25_paragraphs(basic_prompt, top_k=number_of_examples)\n",
        "    unique_paragraphs = list(set(related_paragraphs + bm25_paragraphs))\n",
        "\n",
        "    rag_prompt = basic_prompt + \"\\n\" + \"\\n\"\n",
        "    rag_prompt += \"Example information that can be used while answering the question:\\n\"\n",
        "    if rag_option == \"both\":\n",
        "        rag_prompt += \"\\n\".join([\"=> \" + p for p in unique_paragraphs])\n",
        "    elif rag_option == \"bm25\":\n",
        "        rag_prompt += \"\\n\".join([\"=> \" + p for p in bm25_paragraphs])\n",
        "    elif rag_option == \"vector\":\n",
        "        rag_prompt += \"\\n\".join([\"=> \" + p for p in related_paragraphs])\n",
        "    return rag_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a37cbb26",
      "metadata": {
        "id": "a37cbb26"
      },
      "source": [
        "LLM inference with enriched prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d56b40",
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_inference_endpoint(url, model_id, prompt):\n",
        "    try:\n",
        "        # Text Generation\n",
        "        print(f\"Sending request to {url}\")\n",
        "        response = requests.post(\n",
        "            url,\n",
        "            json={\n",
        "                \"prompt\": \"Answer the following question according to the paragraphs provided to you.\\n\" + prompt,\n",
        "                \"model_id\": model_id,\n",
        "                \"engine\": \"huggingface\",\n",
        "            }\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        result = response.json()\n",
        "        print(f\"Response received:\")\n",
        "        pprint.pprint(result['response'])\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error making request: {e}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding response: {e}\")\n",
        "        print(f\"Raw response: {result['response']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "786ae741",
      "metadata": {},
      "source": [
        "Number of RAG examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad84f648",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_OF_EXAMPLES = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e2b988",
      "metadata": {},
      "source": [
        "Model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edc32ddc",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ID = \"Qwen/Qwen2.5-Coder-7B-Instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9dc3555",
      "metadata": {},
      "source": [
        "Sample questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a034ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_questions = [\n",
        "    \"i am a graduate student and i got an incomplete from one of my courses. when will the final letter grade announced?\",\n",
        "    \"i haven't paid my dormitory payment, can i still apply for being an exchange student in northern cyprus?\",\n",
        "    \"i would like to apply for a graduate program in metu, what are the requirements for candidates?\",\n",
        "    \"when is the last time for finding a thesis supervisor for a master's program?\",\n",
        "    \"what is the lowest grade for scholarship cancellation?\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb6d3885",
      "metadata": {},
      "source": [
        "Prepare user prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1e312a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"http://<your host URL>:8080/api/inference\"\n",
        "\n",
        "user_prompt = sample_questions[4]\n",
        "\n",
        "\n",
        "print(\"Zero shot prompt:\")\n",
        "print(\"---\")\n",
        "pprint.pprint(user_prompt)\n",
        "\n",
        "rag_prompt = get_enriched_llm_prompt(basic_prompt=user_prompt, number_of_examples=NUM_OF_EXAMPLES, \n",
        "                                     rag_option=\"both\")\n",
        "\n",
        "print(\"Enriched prompt:\")\n",
        "print(\"--\")\n",
        "pprint.pprint(rag_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6236ecba",
      "metadata": {},
      "source": [
        "Run inference with enriched prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f8245e",
      "metadata": {},
      "outputs": [],
      "source": [
        "call_inference_endpoint(url, model_id=MODEL_ID, prompt=rag_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9b2c245",
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_prompt = get_enriched_llm_prompt(basic_prompt=user_prompt, number_of_examples=NUM_OF_EXAMPLES, \n",
        "                                     rag_option=\"vector\")\n",
        "\n",
        "print(\"Enriched prompt:\")\n",
        "print(\"--\")\n",
        "pprint.pprint(rag_prompt)\n",
        "\n",
        "call_inference_endpoint(url, model_id=MODEL_ID, prompt=rag_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f5f83c",
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_prompt = get_enriched_llm_prompt(basic_prompt=user_prompt, number_of_examples=NUM_OF_EXAMPLES, \n",
        "                                     rag_option=\"bm25\")\n",
        "\n",
        "print(\"Enriched prompt:\")\n",
        "print(\"--\")\n",
        "pprint.pprint(rag_prompt)\n",
        "\n",
        "call_inference_endpoint(url, model_id=MODEL_ID, prompt=rag_prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mtl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
